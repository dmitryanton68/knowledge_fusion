{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Continuous training on letters after training on digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "try:\n",
    "    import accimage\n",
    "except ImportError:\n",
    "    accimage = None\n",
    "\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from SpykeTorch import snn\n",
    "from SpykeTorch import functional as sf\n",
    "from SpykeTorch import visualization as vis\n",
    "from SpykeTorch import utils\n",
    "\n",
    "import struct\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#import import_ipynb\n",
    "#from MozafariMNIST2018_class import MozafariMNIST2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rule\n",
    "\n",
    "class STDP(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_layer, learning_rate, use_stabilizer = True, lower_bound = 0, upper_bound = 1):\n",
    "        super(STDP, self).__init__()\n",
    "        self.conv_layer = conv_layer\n",
    "        if isinstance(learning_rate, list):\n",
    "            self.learning_rate = learning_rate\n",
    "        else:\n",
    "            self.learning_rate = [learning_rate] * conv_layer.out_channels\n",
    "        for i in range(conv_layer.out_channels):\n",
    "            self.learning_rate[i] = (Parameter(torch.tensor([self.learning_rate[i][0]])),\n",
    "                            Parameter(torch.tensor([self.learning_rate[i][1]])))\n",
    "            self.register_parameter('ltp_' + str(i), self.learning_rate[i][0])\n",
    "            self.register_parameter('ltd_' + str(i), self.learning_rate[i][1])\n",
    "            self.learning_rate[i][0].requires_grad_(False)\n",
    "            self.learning_rate[i][1].requires_grad_(False)\n",
    "        self.use_stabilizer = use_stabilizer\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "\n",
    "    def get_pre_post_ordering(self, input_spikes, output_spikes, winners):\n",
    "\n",
    "        # accumulating input and output spikes to get latencies\n",
    "        input_latencies = torch.sum(input_spikes, dim=0)\n",
    "        output_latencies = torch.sum(output_spikes, dim=0)\n",
    "        result = []\n",
    "        for winner in winners:\n",
    "            # generating repeated output tensor with the same size of the receptive field\n",
    "            out_tensor = torch.ones(*self.conv_layer.kernel_size, device=output_latencies.device) * output_latencies[winner]\n",
    "            # slicing input tensor with the same size of the receptive field centered around winner\n",
    "            # since there is no padding, there is no need to shift it to the center\n",
    "            in_tensor = input_latencies[:,winner[-2]:winner[-2]+self.conv_layer.kernel_size[-2],winner[-1]:winner[-1]+self.conv_layer.kernel_size[-1]]\n",
    "            result.append(torch.ge(in_tensor,out_tensor))\n",
    "        return result\n",
    "\n",
    "    # simple STDP rule with weights freezing  \n",
    "    # gets prepost pairings, winners, weights, and learning rates (all shoud be tensors)\n",
    "    def forward(self, input_spikes, potentials, output_spikes, winners=None, \\\n",
    "                freeze_tensor=None, kwta = 1, inhibition_radius = 0):\n",
    "        \n",
    "        if winners is None:\n",
    "            winners = sf.get_k_winners(potentials, kwta, inhibition_radius, output_spikes)\n",
    "        pairings = self.get_pre_post_ordering(input_spikes, output_spikes, winners)\n",
    "\n",
    "        lr = torch.zeros_like(self.conv_layer.weight)\n",
    "        for i in range(len(winners)):\n",
    "            f = winners[i][0]\n",
    "            lr[f] = torch.where(pairings[i], *(self.learning_rate[f]))\n",
    "\n",
    "        # additional script for weights freezing    \n",
    "        if freeze_tensor is None:\n",
    "            self.conv_layer.weight += lr * ((self.conv_layer.weight-self.lower_bound) * \\\n",
    "                                (self.upper_bound-self.conv_layer.weight) if self.use_stabilizer else 1)\n",
    "        else:\n",
    "            ones_like_freeze_tensor = torch.full_like(freeze_tensor, 1)\n",
    "            zero_like_freeze_tensor = torch.zeros_like(freeze_tensor)\n",
    "\n",
    "            # condition 'freeze_tensor > 0.01' is stronger version of 'freeze_tensor > 0' for insure\n",
    "            anti_freeze_tensor_byte = torch.where(freeze_tensor > 0.01, zero_like_freeze_tensor, ones_like_freeze_tensor)\n",
    "            self.conv_layer.weight += lr * ((self.conv_layer.weight-self.lower_bound) * \\\n",
    "                                (self.upper_bound-self.conv_layer.weight) if self.use_stabilizer else 1) * \\\n",
    "                                anti_freeze_tensor_byte\n",
    "\n",
    "        self.conv_layer.weight.clamp_(self.lower_bound, self.upper_bound)\n",
    "\n",
    "    def update_learning_rate(self, feature, ap, an):\n",
    "\n",
    "        self.learning_rate[feature][0][0] = ap\n",
    "        self.learning_rate[feature][1][0] = an\n",
    "\n",
    "    def update_all_learning_rate(self, ap, an):\n",
    "\n",
    "        for feature in range(self.conv_layer.out_channels):\n",
    "            self.learning_rate[feature][0][0] = ap\n",
    "            self.learning_rate[feature][1][0] = an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class MozafariMNIST2018(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout=0.5, dropout_procedure = False):\n",
    "        \n",
    "        super(MozafariMNIST2018, self).__init__()\n",
    "\n",
    "        self.conv1 = snn.Convolution(6, 30, 5, 0.8, 0.05)\n",
    "        self.conv1_t = 15\n",
    "        self.k1 = 5\n",
    "        self.r1 = 3\n",
    "\n",
    "        self.conv2 = snn.Convolution(30, 250, 3, 0.8, 0.05)\n",
    "        self.conv2_t = 10\n",
    "        self.k2 = 8\n",
    "        self.r2 = 1\n",
    "\n",
    "        self.conv3 = snn.Convolution(250, 200, 5, 0.8, 0.05)\n",
    "        self.number_of_features = 200\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.stdp1 = STDP(self.conv1, (0.004, -0.003))                         \n",
    "        self.stdp2 = STDP(self.conv2, (0.004, -0.003))                         \n",
    "        self.stdp3 = STDP(self.conv3, (0.004, -0.003), False, 0.2, 0.8)        \n",
    "        self.anti_stdp3 = STDP(self.conv3, (-0.004, 0.0005), False, 0.2, 0.8)  \n",
    "        self.max_ap = Parameter(torch.Tensor([0.15]))\n",
    "\n",
    "        self.decision_map = []\n",
    "        for i in range(10):\n",
    "            self.decision_map.extend([i]*20)\n",
    "\n",
    "        self.ctx = {\"input_spikes\":None, \"potentials\":None, \\\n",
    "                    \"output_spikes\":None, \"winners\":None, \\\n",
    "                    \"freeze_tensor\":None}                           # freeze_tensor was added             \n",
    "        self.spk_cnt1 = 0\n",
    "        self.spk_cnt2 = 0\n",
    "        \n",
    "        self.dropout_procedure = dropout_procedure\n",
    "        \n",
    "    def forward(self, input, max_layer, freeze_tensor=None):    # freeze_tensor was added\n",
    "        \n",
    "        input = sf.pad(input.float(), (2,2,2,2), 0)\n",
    "        \n",
    "        if self.training:\n",
    "            pot = self.conv1(input)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "            if max_layer == 1:\n",
    "                self.spk_cnt1 += 1\n",
    "                if self.spk_cnt1 >= 500:\n",
    "                    self.spk_cnt1 = 0\n",
    "                    ap = torch.tensor(self.stdp1.learning_rate[0][0].item(), device=self.stdp1.learning_rate[0][0].device) * 2\n",
    "                    ap = torch.min(ap, self.max_ap)\n",
    "                    an = ap * -0.75\n",
    "                    self.stdp1.update_all_learning_rate(ap.item(), an.item())\n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k1, self.r1, spk)\n",
    "                self.ctx[\"input_spikes\"] = input\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            spk_in = sf.pad(sf.pooling(spk, 2, 2), (1,1,1,1))\n",
    "            pot = self.conv2(spk_in)\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "            if max_layer == 2:\n",
    "                self.spk_cnt2 += 1\n",
    "                if self.spk_cnt2 >= 500:\n",
    "                    self.spk_cnt2 = 0\n",
    "                    ap = torch.tensor(self.stdp2.learning_rate[0][0].item(), device=self.stdp2.learning_rate[0][0].device) * 2\n",
    "                    ap = torch.min(ap, self.max_ap)\n",
    "                    an = ap * -0.75\n",
    "                    self.stdp2.update_all_learning_rate(ap.item(), an.item())\n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k2, self.r2, spk)\n",
    "                self.ctx[\"input_spikes\"] = spk_in\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            spk_in = sf.pad(sf.pooling(spk, 3, 3), (2,2,2,2))\n",
    "            pot = self.conv3(spk_in)           \n",
    "            \n",
    "            if self.dropout_procedure:\n",
    "                dropout = torch.ones(self.number_of_features) * self.dropout\n",
    "                to_be_dropped = torch.bernoulli(dropout).nonzero()   \n",
    "                sf.feature_inhibition_(pot, to_be_dropped)\n",
    "            \n",
    "            spk = sf.fire(pot)\n",
    "            winners = sf.get_k_winners(pot, 1, 0, spk)\n",
    "            self.ctx[\"input_spikes\"] = spk_in\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            self.ctx[\"freeze_tensor\"] = freeze_tensor\n",
    "\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return output\n",
    "        \n",
    "        else:\n",
    "            pot = self.conv1(input)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "            if max_layer == 1:\n",
    "                return spk, pot\n",
    "            \n",
    "            pot = self.conv2(sf.pad(sf.pooling(spk, 2, 2), (1,1,1,1)))\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "            if max_layer == 2:\n",
    "                return spk, pot\n",
    "            pot = self.conv3(sf.pad(sf.pooling(spk, 3, 3), (2,2,2,2)))\n",
    "            spk = sf.fire(pot)\n",
    "            winners = sf.get_k_winners(pot, 1, 0, spk)\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return output\n",
    "\n",
    "    def stdp(self, layer_idx):\n",
    "        if layer_idx == 1:\n",
    "            self.stdp1(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"], self.ctx[\"freeze_tensor\"])\n",
    "        if layer_idx == 2:\n",
    "            self.stdp2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"], self.ctx[\"freeze_tensor\"])\n",
    "\n",
    "    def update_learning_rates(self, stdp_ap, stdp_an, anti_stdp_ap, anti_stdp_an):\n",
    "               \n",
    "        self.stdp3.update_all_learning_rate(stdp_ap, stdp_an)\n",
    "        self.anti_stdp3.update_all_learning_rate(anti_stdp_an, anti_stdp_ap)  \n",
    " \n",
    "    def reward(self):\n",
    "        self.stdp3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"], self.ctx[\"freeze_tensor\"])\n",
    "\n",
    "    def punish(self):\n",
    "        self.anti_stdp3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"], self.ctx[\"freeze_tensor\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "\n",
    "def train_unsupervise(network, data, layer_idx):\n",
    "    network.train()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "        network(data_in, layer_idx)\n",
    "        network.stdp(layer_idx)\n",
    "\n",
    "def train_rl(network, data, target, freeze_tensor=None):\n",
    "    network.train()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        d = network(data_in, 3, freeze_tensor)    # freeze_tensor was added\n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1\n",
    "                network.reward() \n",
    "            else:\n",
    "                perf[1]+=1\n",
    "                network.punish()  \n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data)\n",
    "\n",
    "def test(network, data, target):\n",
    "    network.eval()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        d = network(data_in, 3)\n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1\n",
    "            else:\n",
    "                perf[1]+=1\n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "class S1C1Transform:\n",
    "    \n",
    "    def __init__(self, filter, PIL_type=False, timesteps = 15):\n",
    "        self.PIL_type = PIL_type\n",
    "        self.to_pil_image = transforms.ToPILImage()    \n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.filter = filter\n",
    "        self.temporal_transform = utils.Intensity2Latency(timesteps)\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        #if self.cnt % 10000 == 0:\n",
    "        #    print(f'{self.cnt} images')\n",
    "        if self.PIL_type:\n",
    "            image = self.to_pil_image(image)\n",
    "        self.cnt+=1\n",
    "        image = self.to_tensor(image) * 255\n",
    "        image.unsqueeze_(0)\n",
    "        image = self.filter(image)\n",
    "        image = sf.local_normalization(image, 8)\n",
    "        temporal_image = self.temporal_transform(image)\n",
    "        return temporal_image.sign().byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "kernels = [ utils.DoGKernel(3,3/9,6/9),\n",
    "            utils.DoGKernel(3,6/9,3/9),\n",
    "            utils.DoGKernel(7,7/9,14/9),\n",
    "            utils.DoGKernel(7,14/9,7/9),\n",
    "            utils.DoGKernel(13,13/9,26/9),\n",
    "            utils.DoGKernel(13,26/9,13/9)]\n",
    "\n",
    "filter = utils.Filter(kernels, padding = 6, thresholds = 50)\n",
    "\n",
    "s1c1 = S1C1Transform(filter)\n",
    "s1c1_PIL = S1C1Transform(filter, PIL_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tensors, transform=None):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_graph(parametr_set):\n",
    "\n",
    "    plt.subplots(figsize=(15, 5))\n",
    "\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['train']*100, color='cyan', label='train')\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['test']*100, color='blue', marker = 'o', label='test')\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['test_previous']*100, linestyle = ':', color='red', label='test of previous images')\n",
    "    plt.xlabel('epochs', loc='right', fontsize=17)\n",
    "    plt.ylabel('accuracy, %',  loc='top', fontsize=17)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training of the 3-rd layer\n",
    "\n",
    "def third_layer(file_name_net, file_name_csv, adaptive_int, previous_epochs, epochs, \n",
    "                train_loader, test_loader, test_previous_loader,\n",
    "                model, apr, anr, app, anp, parametr_set, \n",
    "                steps=None, percent=20, value_for_moved_weights=0.8,\n",
    "                it_continues=False, freeze_procedure=False):  \n",
    "    \n",
    "    '''\n",
    "    file_name_net - name of file for saving state_dict of model\n",
    "    file_name_csv - name of file for saving parameters of model in each epoch\n",
    "    adaptive_int - learning rate parameter\n",
    "    previous_epochs - if before model had training in current period\n",
    "    it_continues - is it continue of 3-rd layer training or not (False or True)\n",
    "    percent - percent of moving weights (calculated from the number of high range weights)\n",
    "    '''\n",
    "\n",
    "    adaptive_min=0 \n",
    "\n",
    "    if not it_continues:\n",
    "\n",
    "        previous_epochs = 0\n",
    "        counter = 0\n",
    "\n",
    "        apr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * apr\n",
    "        anr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * anr\n",
    "        app_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * app\n",
    "        anp_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * anp\n",
    "        \n",
    "        best_train = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "        best_test = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "        best_test_previous = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "\n",
    "    else:\n",
    "      \n",
    "        if len(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch']) == 1:\n",
    "            optim_index = int(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            optim_index = int(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch'].tolist()[-1])\n",
    "\n",
    "        if len(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch']) == 1:\n",
    "            best_train_index = int(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            best_train_index = int(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch'].tolist()[-1])\n",
    "\n",
    "        if len(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch']) == 1:\n",
    "            best_test_previous_index = int(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            best_test_previous_index = int(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch'].tolist()[-1])\n",
    "        \n",
    "        max_index = int(parametr_set.index.max())\n",
    "        counter = (max_index + 1)\n",
    "\n",
    "        param_best_train = parametr_set['train'].iloc[best_train_index]\n",
    "        param_best_test = parametr_set['test'].iloc[optim_index]\n",
    "        param_best_test_previous = parametr_set['test_previous'].iloc[best_test_previous_index]\n",
    "\n",
    "        apr_adapt = parametr_set['apr_adapt'].iloc[optim_index]\n",
    "        anr_adapt = parametr_set['anr_adapt'].iloc[optim_index]\n",
    "        app_adapt = parametr_set['app_adapt'].iloc[optim_index]\n",
    "        anp_adapt = parametr_set['anp_adapt'].iloc[optim_index]\n",
    "        \n",
    "        for i in range(len(model.stdp3.learning_rate)):\n",
    "            model.stdp3.learning_rate[i][0].fill_(parametr_set['stdp3.learning_rate[0]'].iloc[optim_index])\n",
    "            model.stdp3.learning_rate[i][1].fill_(parametr_set['stdp3.learning_rate[1]'].iloc[optim_index])\n",
    "            model.anti_stdp3.learning_rate[0][0].fill_(parametr_set['anti_stdp3.learning_rate[0]'].iloc[optim_index])\n",
    "            model.anti_stdp3.learning_rate[0][0].fill_(parametr_set['anti_stdp3.learning_rate[1]'].iloc[optim_index])\n",
    "\n",
    "        best_train = np.array([param_best_train,1-param_best_train,0.0,best_train_index]) # correct, wrong, silence, epoch\n",
    "        best_test = np.array([param_best_test,1-param_best_test,0.0,optim_index]) # correct, wrong, silence, epoch\n",
    "        best_test_previous = np.array([param_best_test_previous,1-param_best_test_previous,0.0,best_test_previous_index]) # correct, wrong, silence, epoch\n",
    "    \n",
    "    # list of 3-rd layer weights\n",
    "\n",
    "    dim_0, dim_1, dim_2, dim_3 = tuple(model.conv3.weight.size())\n",
    "    total_size = dim_0 * dim_1 * dim_2 * dim_3\n",
    "  \n",
    "    # indexes of weights\n",
    "    indexes_i = []    \n",
    "    indexes_j = []        \n",
    "    indexes_k = []        \n",
    "    indexes_m = []    \n",
    "    \n",
    "    # values of weights\n",
    "    item_values = []  \n",
    "    \n",
    "    for i in range(dim_0):\n",
    "        for j in range(dim_1):\n",
    "            for k in range(dim_2):\n",
    "                for m in range(dim_3):\n",
    "                    indexes_i.append(i)\n",
    "                    indexes_j.append(j)\n",
    "                    indexes_k.append(k)\n",
    "                    indexes_m.append(m)\n",
    "                    item_values.append(model.conv3.weight[i][j][k][m].item())\n",
    "\n",
    "    indexes_dim_0 = pd.Series(indexes_i, name='dim_0') \n",
    "    indexes_dim_1 = pd.Series(indexes_j, name='dim_1')\n",
    "    indexes_dim_2 = pd.Series(indexes_k, name='dim_2')\n",
    "    indexes_dim_3 = pd.Series(indexes_m, name='dim_3')\n",
    "    item_values = pd.Series(item_values, name='value_0')\n",
    "            \n",
    "    conv3_data = pd.concat([item_values, indexes_dim_0, indexes_dim_1, indexes_dim_2, indexes_dim_3], axis=1)\n",
    "    \n",
    "    high_percent = 85 #percent of high range weights\n",
    "    percentile_value = np.percentile(item_values, high_percent)\n",
    "    \n",
    "    conv3_data['low_range_0'] = 0\n",
    "    conv3_data.loc[conv3_data['value_0'] < percentile_value,'low_range_0'] = 1\n",
    "    \n",
    "    # indexes of freeze weights of third layer before training on the next set                   \n",
    "    conv3_data['freeze_weights'] = 0\n",
    "    conv3_data.loc[conv3_data['value_0'] > percentile_value,'freeze_weights'] = 1      \n",
    "    \n",
    "    if freeze_procedure:\n",
    "        print(f\"During training {conv3_data['freeze_weights'].sum()} weights \"\n",
    "              f\"({conv3_data['freeze_weights'].sum()/total_size*100 :.1f}%) will be freezed\")\n",
    "        \n",
    "        weights_threshold = nn.Threshold(percentile_value, 0)\n",
    "        freeze_tensor = weights_threshold(model.conv3.weight)                     \n",
    "        freeze_list = conv3_data.loc[conv3_data['freeze_weights'] == 1, 'value_0'].to_numpy()\n",
    "    else:\n",
    "        freeze_list=[]\n",
    "        freeze_tensor=None\n",
    "\n",
    "    try:\n",
    "        high_range_counter = conv3_data['low_range_0'].value_counts()[0] \n",
    "    except:\n",
    "        high_range_counter = 1\n",
    " \n",
    "    moving_quantity = int((percent/100)*high_range_counter)      #quantity of moving items in each epoch\n",
    "    #quantity of moving items in each epoch is calculated without taking in account freezed weights\n",
    "    \n",
    "    if steps is None:\n",
    "        steps = int(total_size*high_percent/(100*moving_quantity))   #steps of weights moving \n",
    "    elif steps == 0:\n",
    "        print(f'Training will be performed without weight moving.')\n",
    "    else:\n",
    "        print(f'Weight moving will be during {steps} epochs')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        seconds_epoch_0 = time.time() \n",
    "        \n",
    "        print('-'*50)\n",
    "        print(\"Epoch #: \", epoch + previous_epochs)\n",
    "        \n",
    "        perf_train = np.array([0.0,0.0,0.0]) \n",
    "        \n",
    "        for data,targets in train_loader:\n",
    "                \n",
    "            if epoch < steps: \n",
    "                \n",
    "                print(f'Values of high range weights in epoch#{epoch} [{percentile_value :.3f}:0.800] (top {100-high_percent}%)')\n",
    "                low_range_indexes = list(conv3_data.index[(conv3_data['low_range_'+str(epoch)] == 1)&(conv3_data['freeze_weights'] == 0)])\n",
    "                moving_items = random.sample(low_range_indexes, np.minimum(moving_quantity, len(low_range_indexes)))\n",
    "                moving_indexes = conv3_data.loc[conv3_data.index.isin(moving_items)]\n",
    "\n",
    "                print(f'Quantity of moving points in epoch#{epoch + previous_epochs} = {len(moving_indexes.index)} items' \n",
    "                      f' ({len(moving_indexes.index)/(total_size-high_range_counter)*100 :.1f}% of moving points)')\n",
    "\n",
    "                for q in range(len(moving_indexes.index)):\n",
    "                    model.conv3.weight \\\n",
    "                    [moving_indexes['dim_0'].iloc[q]][moving_indexes['dim_1'].iloc[q]][moving_indexes['dim_2'].iloc[q]][moving_indexes['dim_3'].iloc[q]]. \\\n",
    "                    fill_(np.random.normal(loc=value_for_moved_weights, scale=0.05))  \n",
    "                \n",
    "            perf_train_batch = train_rl(model, data, targets, freeze_tensor)        \n",
    "    \n",
    "            if epoch < steps:  \n",
    "            \n",
    "                # new values of weights (after learning)\n",
    "                item_values = []       \n",
    "                for i in range(dim_0):\n",
    "                    for j in range(dim_1):\n",
    "                        for k in range(dim_2):\n",
    "                            for m in range(dim_3):\n",
    "                                item_values.append(model.conv3.weight[i][j][k][m].item())\n",
    "            \n",
    "                item_values = pd.Series(item_values, name='value_'+str(epoch+1))\n",
    "                percentile_value = np.percentile(item_values, high_percent) #new cutting off high range weights\n",
    "                conv3_data = pd.concat([conv3_data, item_values], axis=1)\n",
    "                \n",
    "                conv3_data['low_range_'+str(epoch+1)] = 0\n",
    "                conv3_data.loc[conv3_data['value_'+str(epoch+1)] < percentile_value,'low_range_'+str(epoch+1)] = 1\n",
    "       \n",
    "            #update adaptive learning rates\n",
    "            apr_adapt = apr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "            anr_adapt = anr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "            app_adapt = app * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "            anp_adapt = anp * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "            parametr_set.loc[counter, 'epoch'] = epoch + previous_epochs\n",
    "            parametr_set.loc[counter, 'apr_adapt'] = apr_adapt\n",
    "            parametr_set.loc[counter, 'anr_adapt'] = anr_adapt\n",
    "            parametr_set.loc[counter, 'app_adapt'] = app_adapt\n",
    "            parametr_set.loc[counter, 'anp_adapt'] = anp_adapt\n",
    "            parametr_set.loc[counter, 'stdp3.learning_rate[0]'] = model.stdp3.learning_rate[0][0].item()\n",
    "            parametr_set.loc[counter, 'stdp3.learning_rate[1]'] = model.stdp3.learning_rate[0][1].item()\n",
    "            parametr_set.loc[counter, 'anti_stdp3.learning_rate[0]'] = model.anti_stdp3.learning_rate[0][0].item()\n",
    "            parametr_set.loc[counter, 'anti_stdp3.learning_rate[1]'] = model.anti_stdp3.learning_rate[0][1].item()\n",
    "            parametr_set.loc[counter, 'train'] = perf_train_batch[0]\n",
    "\n",
    "            model.update_learning_rates(apr_adapt, anr_adapt, app_adapt, anp_adapt)\n",
    "            perf_train += perf_train_batch\n",
    "            \n",
    "        perf_train /= len(train_loader)\n",
    "\n",
    "        if best_train[0] <= perf_train[0]:\n",
    "            best_train = np.append(perf_train, epoch + previous_epochs)\n",
    "        print(f\"Current Train: {perf_train[0]*100 :.2f}%\")\n",
    "\n",
    "        for data,targets in test_loader:\n",
    "            perf_test = test(model, data, targets)\n",
    "            parametr_set.loc[counter, 'test'] = perf_test[0]\n",
    "            if best_test[0] <= perf_test[0]:\n",
    "                best_test = np.append(perf_test, epoch + previous_epochs)\n",
    "                torch.save(model.state_dict(), file_name_net)\n",
    "            print(f\"Current Test: {perf_test[0]*100 :.2f}%\")\n",
    "\n",
    "        if isinstance(test_previous_loader, DataLoader):\n",
    "            for data,targets in test_previous_loader:\n",
    "                perf_test_previous = test(model, data, targets)\n",
    "                parametr_set.loc[counter, 'test_previous'] = perf_test_previous[0]\n",
    "                if best_test_previous[0] <= perf_test_previous[0]:\n",
    "                    best_test_previous = np.append(perf_test_previous, epoch + previous_epochs)\n",
    "                print(f\"Current Test Previous: {perf_test_previous[0]*100 :.2f}%\")\n",
    "                \n",
    "        else:\n",
    "            parametr_set.loc[counter, 'test_previous'] = 0\n",
    "            \n",
    "        counter += 1\n",
    "                                                 \n",
    "        seconds_epoch_1 = time.time()  \n",
    "        print(f'Operational time of epoch #{epoch + previous_epochs}: '\n",
    "                  f'{int((seconds_epoch_1 - seconds_epoch_0)//60)} min {int((seconds_epoch_1 - seconds_epoch_0)%60)} sec') \n",
    "    \n",
    "    parametr_set.to_csv(file_name_csv)\n",
    "    \n",
    "    print('=='*10, 'SUMMARY', '=='*10)\n",
    "    print(f\"        Best Train: {best_train[0]*100 :.2f}% on {best_train[3] :.0f} epoch\")\n",
    "    print(f\"         Best Test: {best_test[0]*100 :.2f}% on {best_test[3] :.0f} epoch\")\n",
    "    print(f\"Best Test Previous: {best_test_previous[0]*100 :.2f}% on {best_test_previous[3] :.0f} epoch\")\n",
    "    \n",
    "    return parametr_set, counter, (previous_epochs+epochs), apr, anr, app, anp, conv3_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of capital letters\n",
    "24000 train images + 4000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of 10 capital letters from EMNIST\n",
    "path = f'./data/EMNIST_own/capital_letters/'\n",
    "\n",
    "test_letter_labels = torch.load(f'{path}Mozafari_capital_letters_test_labels.pt', map_location=torch.device('cpu'))\n",
    "test_letters = torch.load(f'{path}Mozafari_capital_letters_test_images.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "train_letter_labels = torch.load(f'{path}Mozafari_capital_letters_train_labels.pt', map_location=torch.device('cpu'))\n",
    "train_letters = torch.load(f'{path}Mozafari_capital_letters_train_images.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element permutation\n",
    "\n",
    "train_order_l = torch.randperm(train_letter_labels.shape[0])\n",
    "test_order_l = torch.randperm(test_letter_labels.shape[0])\n",
    "\n",
    "train_letter_labels = train_letter_labels[train_order_l].view(train_letter_labels.size())\n",
    "train_letters = train_letters[train_order_l].view(train_letters.size())\n",
    "\n",
    "test_letter_labels = test_letter_labels[test_order_l].view(test_letter_labels.size())\n",
    "test_letters = test_letters[test_order_l].view(test_letters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24000]), torch.Size([4000]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_letter_labels.size(), test_letter_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_letter_set = CustomTensorDataset(tensors=(train_letters, train_letter_labels), transform=s1c1_PIL)\n",
    "test_letter_set = CustomTensorDataset(tensors=(test_letters, test_letter_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_letter_loader = DataLoader(train_letter_set, batch_size=len(train_letter_set))\n",
    "test_letter_loader = DataLoader(test_letter_set, batch_size=len(test_letter_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of 10 MNIST digits\n",
    "Reduction the set of 60000 train + 10000 test images to the set of 24000 train + 4000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the set of 10 digit images, the same size as the set of letters (2400 trains + 400 tests per class)\n",
    "\n",
    "# the MNIST data was pre-divided into 10 classes\n",
    "path = f'./data/MNIST_0_1_2_3_4_5_6_7_8_9/'\n",
    "\n",
    "for i in classes: \n",
    "    globals()[f'train_digit_{i}_images'] = torch.load(f'{path}train_images_{i}.pt', map_location=torch.device('cpu'))[0:2400]\n",
    "    globals()[f'train_digit_{i}_labels'] = torch.load(f'{path}train_labels_{i}.pt', map_location=torch.device('cpu'))[0:2400]\n",
    "    globals()[f'test_digit_{i}_images'] = torch.load(f'{path}test_images_{i}.pt', map_location=torch.device('cpu'))[0:400]\n",
    "    globals()[f'test_digit_{i}_labels'] = torch.load(f'{path}test_labels_{i}.pt', map_location=torch.device('cpu'))[0:400]\n",
    "\n",
    "train_MNIST_labels = globals()[f'train_digit_0_labels']\n",
    "train_MNIST_images = globals()[f'train_digit_0_images']\n",
    "test_MNIST_labels = globals()[f'test_digit_0_labels']\n",
    "test_MNIST_images = globals()[f'test_digit_0_images']                                 \n",
    "\n",
    "for i in range(1, 10):\n",
    "    train_MNIST_labels = torch.cat((train_MNIST_labels, globals()[f'train_digit_{i}_labels']), 0)\n",
    "    train_MNIST_images = torch.cat((train_MNIST_images, globals()[f'train_digit_{i}_images']), 0)\n",
    "\n",
    "    test_MNIST_labels = torch.cat((test_MNIST_labels, globals()[f'test_digit_{i}_labels']), 0)\n",
    "    test_MNIST_images = torch.cat((test_MNIST_images, globals()[f'test_digit_{i}_images']), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24000]), torch.Size([4000]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_MNIST_labels.size(), test_MNIST_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element permutation\n",
    "\n",
    "train_order = torch.randperm(train_MNIST_labels.shape[0])\n",
    "test_order = torch.randperm(test_MNIST_labels.shape[0])\n",
    "\n",
    "train_MNIST_labels = train_MNIST_labels[train_order].view(train_MNIST_labels.size())\n",
    "train_MNIST_images = train_MNIST_images[train_order].view(train_MNIST_images.size())\n",
    "\n",
    "test_MNIST_labels = test_MNIST_labels[test_order].view(test_MNIST_labels.size())\n",
    "test_MNIST_images = test_MNIST_images[test_order].view(test_MNIST_images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MNIST_set = CustomTensorDataset(tensors=(train_MNIST_images, train_MNIST_labels), transform=s1c1_PIL)\n",
    "test_MNIST_set = CustomTensorDataset(tensors=(test_MNIST_images, test_MNIST_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_MNIST_loader = DataLoader(train_MNIST_set, batch_size=len(train_MNIST_set))\n",
    "test_MNIST_loader = DataLoader(test_MNIST_set, batch_size=len(test_MNIST_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mozafari = MozafariMNIST2018()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "if use_cuda:\n",
    "    mozafari.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MozafariMNIST2018(\n",
       "  (conv1): Convolution()\n",
       "  (conv2): Convolution()\n",
       "  (conv3): Convolution()\n",
       "  (stdp1): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (stdp2): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (stdp3): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (anti_stdp3): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mozafari.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous training on letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving parameters before training on digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_from_scratch = {'stdp1': [mozafari.stdp1.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp1.learning_rate[0][1].item()],\n",
    "                              'stdp2': [mozafari.stdp2.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp2.learning_rate[0][1].item()],\n",
    "                              'stdp3': [mozafari.stdp3.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp3.learning_rate[0][1].item()],\n",
    "                              'anti_stdp3': [mozafari.anti_stdp3.learning_rate[0][0].item(), \n",
    "                                             mozafari.anti_stdp3.learning_rate[0][1].item()]\n",
    "                             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation 1st and 2nd layers of SNN trained on 24,000 images of digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file \"saved_24000_digits_l1_0.net\" is the result \n",
    "# of the file \"0_Initial_training_on_digits.ipynb\"\n",
    "mozafari.load_state_dict(torch.load(\"saved_24000_digits_l1_0.net\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file \"saved_24000_digits_l2_0.net\" is the result \n",
    "# of the file \"0_Initial_training_on_digits.ipynb\"\n",
    "mozafari.load_state_dict(torch.load(\"saved_24000_digits_l2_0.net\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the third layer on letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving learning_rates \n",
    "\n",
    "for i in range(len(mozafari.stdp3.learning_rate)):\n",
    "                    mozafari.stdp3.learning_rate[i][0].fill_(learning_rate_from_scratch['stdp3'][0])\n",
    "                    mozafari.stdp3.learning_rate[i][1].fill_(learning_rate_from_scratch['stdp3'][1])\n",
    "                    mozafari.anti_stdp3.learning_rate[i][0].fill_(learning_rate_from_scratch['anti_stdp3'][0])\n",
    "                    mozafari.anti_stdp3.learning_rate[i][1].fill_(learning_rate_from_scratch['anti_stdp3'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial adaptive learning rates\n",
    "\n",
    "apr = mozafari.stdp3.learning_rate[0][0].item()\n",
    "anr = mozafari.stdp3.learning_rate[0][1].item()\n",
    "app = mozafari.anti_stdp3.learning_rate[0][1].item()\n",
    "anp = mozafari.anti_stdp3.learning_rate[0][0].item()\n",
    "               \n",
    "parametr_set = pd.DataFrame(columns=['epoch', 'train', 'test', 'test_previous',   \n",
    "                                 'apr_adapt', 'anr_adapt', 'app_adapt', 'anp_adapt', \n",
    "                                 'stdp3.learning_rate[0]', 'stdp3.learning_rate[1]',\n",
    "                                 'anti_stdp3.learning_rate[0]', 'anti_stdp3.learning_rate[1]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be performed without weight moving.\n",
      "--------------------------------------------------\n",
      "Epoch #:  0\n",
      "Current Train: 62.83%\n",
      "Current Test: 74.02%\n",
      "Current Test Previous: 6.28%\n",
      "Operational time of epoch #0: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  1\n",
      "Current Train: 77.00%\n",
      "Current Test: 76.45%\n",
      "Current Test Previous: 6.45%\n",
      "Operational time of epoch #1: 2 min 0 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  2\n",
      "Current Train: 81.39%\n",
      "Current Test: 81.05%\n",
      "Current Test Previous: 5.75%\n",
      "Operational time of epoch #2: 2 min 0 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  3\n",
      "Current Train: 84.40%\n",
      "Current Test: 82.60%\n",
      "Current Test Previous: 7.10%\n",
      "Operational time of epoch #3: 2 min 0 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  4\n",
      "Current Train: 85.58%\n",
      "Current Test: 84.00%\n",
      "Current Test Previous: 7.10%\n",
      "Operational time of epoch #4: 2 min 0 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  5\n",
      "Current Train: 86.73%\n",
      "Current Test: 84.67%\n",
      "Current Test Previous: 5.25%\n",
      "Operational time of epoch #5: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  6\n",
      "Current Train: 87.62%\n",
      "Current Test: 85.42%\n",
      "Current Test Previous: 6.08%\n",
      "Operational time of epoch #6: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  7\n",
      "Current Train: 88.39%\n",
      "Current Test: 85.88%\n",
      "Current Test Previous: 6.15%\n",
      "Operational time of epoch #7: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  8\n",
      "Current Train: 88.75%\n",
      "Current Test: 86.15%\n",
      "Current Test Previous: 6.48%\n",
      "Operational time of epoch #8: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  9\n",
      "Current Train: 89.16%\n",
      "Current Test: 86.55%\n",
      "Current Test Previous: 7.05%\n",
      "Operational time of epoch #9: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  10\n",
      "Current Train: 89.68%\n",
      "Current Test: 86.55%\n",
      "Current Test Previous: 6.48%\n",
      "Operational time of epoch #10: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  11\n",
      "Current Train: 89.97%\n",
      "Current Test: 86.92%\n",
      "Current Test Previous: 7.12%\n",
      "Operational time of epoch #11: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  12\n",
      "Current Train: 90.24%\n",
      "Current Test: 87.35%\n",
      "Current Test Previous: 7.45%\n",
      "Operational time of epoch #12: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  13\n",
      "Current Train: 90.51%\n",
      "Current Test: 87.33%\n",
      "Current Test Previous: 6.48%\n",
      "Operational time of epoch #13: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  14\n",
      "Current Train: 90.63%\n",
      "Current Test: 87.48%\n",
      "Current Test Previous: 6.80%\n",
      "Operational time of epoch #14: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  15\n",
      "Current Train: 90.93%\n",
      "Current Test: 87.62%\n",
      "Current Test Previous: 7.75%\n",
      "Operational time of epoch #15: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  16\n",
      "Current Train: 91.03%\n",
      "Current Test: 87.88%\n",
      "Current Test Previous: 7.10%\n",
      "Operational time of epoch #16: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  17\n",
      "Current Train: 91.08%\n",
      "Current Test: 87.75%\n",
      "Current Test Previous: 7.60%\n",
      "Operational time of epoch #17: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  18\n",
      "Current Train: 91.27%\n",
      "Current Test: 88.10%\n",
      "Current Test Previous: 7.10%\n",
      "Operational time of epoch #18: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  19\n",
      "Current Train: 91.47%\n",
      "Current Test: 87.85%\n",
      "Current Test Previous: 6.45%\n",
      "Operational time of epoch #19: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  20\n",
      "Current Train: 91.57%\n",
      "Current Test: 87.85%\n",
      "Current Test Previous: 6.95%\n",
      "Operational time of epoch #20: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  21\n",
      "Current Train: 91.72%\n",
      "Current Test: 88.08%\n",
      "Current Test Previous: 6.10%\n",
      "Operational time of epoch #21: 2 min 3 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  22\n",
      "Current Train: 91.81%\n",
      "Current Test: 87.95%\n",
      "Current Test Previous: 6.50%\n",
      "Operational time of epoch #22: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  23\n",
      "Current Train: 91.97%\n",
      "Current Test: 88.05%\n",
      "Current Test Previous: 6.70%\n",
      "Operational time of epoch #23: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  24\n",
      "Current Train: 92.07%\n",
      "Current Test: 88.35%\n",
      "Current Test Previous: 6.50%\n",
      "Operational time of epoch #24: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  25\n",
      "Current Train: 92.15%\n",
      "Current Test: 88.10%\n",
      "Current Test Previous: 6.78%\n",
      "Operational time of epoch #25: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  26\n",
      "Current Train: 92.07%\n",
      "Current Test: 88.25%\n",
      "Current Test Previous: 6.95%\n",
      "Operational time of epoch #26: 2 min 5 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  27\n",
      "Current Train: 92.24%\n",
      "Current Test: 88.55%\n",
      "Current Test Previous: 7.22%\n",
      "Operational time of epoch #27: 2 min 5 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  28\n",
      "Current Train: 92.43%\n",
      "Current Test: 88.60%\n",
      "Current Test Previous: 6.85%\n",
      "Operational time of epoch #28: 2 min 3 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  29\n",
      "Current Train: 92.47%\n",
      "Current Test: 88.45%\n",
      "Current Test Previous: 7.03%\n",
      "Operational time of epoch #29: 2 min 5 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  30\n",
      "Current Train: 92.55%\n",
      "Current Test: 88.50%\n",
      "Current Test Previous: 6.25%\n",
      "Operational time of epoch #30: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  31\n",
      "Current Train: 92.57%\n",
      "Current Test: 88.80%\n",
      "Current Test Previous: 6.20%\n",
      "Operational time of epoch #31: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  32\n",
      "Current Train: 92.76%\n",
      "Current Test: 88.70%\n",
      "Current Test Previous: 7.38%\n",
      "Operational time of epoch #32: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  33\n",
      "Current Train: 92.83%\n",
      "Current Test: 88.78%\n",
      "Current Test Previous: 6.02%\n",
      "Operational time of epoch #33: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  34\n",
      "Current Train: 92.95%\n",
      "Current Test: 88.83%\n",
      "Current Test Previous: 6.28%\n",
      "Operational time of epoch #34: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  35\n",
      "Current Train: 92.99%\n",
      "Current Test: 88.90%\n",
      "Current Test Previous: 6.48%\n",
      "Operational time of epoch #35: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  36\n",
      "Current Train: 93.08%\n",
      "Current Test: 89.15%\n",
      "Current Test Previous: 6.38%\n",
      "Operational time of epoch #36: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  37\n",
      "Current Train: 93.16%\n",
      "Current Test: 89.25%\n",
      "Current Test Previous: 6.22%\n",
      "Operational time of epoch #37: 2 min 2 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  38\n",
      "Current Train: 93.31%\n",
      "Current Test: 89.20%\n",
      "Current Test Previous: 6.12%\n",
      "Operational time of epoch #38: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  39\n",
      "Current Train: 93.39%\n",
      "Current Test: 89.10%\n",
      "Current Test Previous: 6.40%\n",
      "Operational time of epoch #39: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  40\n",
      "Current Train: 93.52%\n",
      "Current Test: 89.22%\n",
      "Current Test Previous: 6.40%\n",
      "Operational time of epoch #40: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  41\n",
      "Current Train: 93.53%\n",
      "Current Test: 89.25%\n",
      "Current Test Previous: 6.28%\n",
      "Operational time of epoch #41: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  42\n",
      "Current Train: 93.60%\n",
      "Current Test: 89.18%\n",
      "Current Test Previous: 6.40%\n",
      "Operational time of epoch #42: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  43\n",
      "Current Train: 93.70%\n",
      "Current Test: 89.50%\n",
      "Current Test Previous: 6.50%\n",
      "Operational time of epoch #43: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  44\n",
      "Current Train: 93.82%\n",
      "Current Test: 89.53%\n",
      "Current Test Previous: 6.50%\n",
      "Operational time of epoch #44: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  45\n",
      "Current Train: 93.85%\n",
      "Current Test: 89.42%\n",
      "Current Test Previous: 6.95%\n",
      "Operational time of epoch #45: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Train: 93.95%\n",
      "Current Test: 89.60%\n",
      "Current Test Previous: 6.55%\n",
      "Operational time of epoch #46: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  47\n",
      "Current Train: 94.05%\n",
      "Current Test: 89.60%\n",
      "Current Test Previous: 6.75%\n",
      "Operational time of epoch #47: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  48\n",
      "Current Train: 94.10%\n",
      "Current Test: 89.83%\n",
      "Current Test Previous: 5.95%\n",
      "Operational time of epoch #48: 2 min 1 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  49\n",
      "Current Train: 94.19%\n",
      "Current Test: 89.83%\n",
      "Current Test Previous: 6.88%\n",
      "Operational time of epoch #49: 2 min 1 sec\n",
      "==================== SUMMARY ====================\n",
      "        Best Train: 94.19% on 49 epoch\n",
      "         Best Test: 89.83% on 49 epoch\n",
      "Best Test Previous: 7.75% on 15 epoch\n"
     ]
    }
   ],
   "source": [
    "# training of the 3-rd layer\n",
    "\n",
    "first_test = third_layer(file_name_net=\"saved_letters_after_digits_total_0.net\",\n",
    "                        file_name_csv='parameter_set_letters_after_digits_0.csv',\n",
    "                        adaptive_int=0.5, previous_epochs=0, epochs=50, \n",
    "                        train_loader=train_letter_loader, \n",
    "                        test_loader=test_letter_loader, \n",
    "                        test_previous_loader=test_MNIST_loader,\n",
    "                        model=mozafari, apr=apr, anr=anr, app=app, anp=anp, \n",
    "                        parametr_set=parametr_set, \n",
    "                        steps=0, percent=0)\n",
    "\n",
    "parametr_set = first_test[0] \n",
    "counter = first_test[1] \n",
    "previous_epochs = first_test[2]\n",
    "apr = first_test[3] \n",
    "anr = first_test[4] \n",
    "app = first_test[5] \n",
    "anp = first_test[6]\n",
    "conv3_data_train = first_test[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "curve_graph(parametr_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
